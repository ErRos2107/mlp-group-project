{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code based on [this code](https://github.com/siyuanzhao/2016-EDM) used in paper \"[Going Deeper with Deep Knowledge Tracing](http://www.educationaldatamining.org/EDM2016/proceedings/paper_133.pdf)\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ASSISTment Data is collected from a web-based automated math tutoring system. Core features include student id, question id & whether or not their answer was correct. \n",
    "\n",
    "There is [a dataset from 2009](https://sites.google.com/site/assistmentsdata/home/assistment-2009-2010-data/skill-builder-data-2009-2010) and is [a dataset from 2015](https://sites.google.com/site/assistmentsdata/home/2015-assistments-skill-builder-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ASSISTDataProvider has a couple of modifications compared to the usual DataProvider.\n",
    " - You need to give it the path to the directory containing the .npz files\n",
    " - you can tell it which_year ('09' or '15')\n",
    " - For each batch, it produces inputs, targets AND target_ids.  \n",
    "     - The target_ids contain indices for extracting a predictions vector from the output of the RNN (exactly like the 2016-EDM code).\n",
    " - There is no .npz file for the validation set. \n",
    "  - Instead, we use k-fold cross validation by first constructing a DataProvider using the training data, and then calling get_k_folds method, which returns k tuples of DataProviders: (train_dp, val_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider import ASSISTDataProvider"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your path to directory containing data files\n",
    "DATA_DIR = '~/Data/'"
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your path to directory containing data files\n",
    "DATA_DIR = '/home/ben/mlp/mlp-group-project/data/assist09'"
>>>>>>> d18c7e7306304373387d2dde163ae84dd1524bb2
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 5,
   "metadata": {},
>>>>>>> d18c7e7306304373387d2dde163ae84dd1524bb2
   "outputs": [],
   "source": [
    "# batch_size is the number students included in each training batch\n",
    "TrainingProvider = ASSISTDataProvider(DATA_DIR, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 6,
>>>>>>> d18c7e7306304373387d2dde163ae84dd1524bb2
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973\n",
      "(1, 10, 293)\n",
      "895\n",
      "895\n"
     ]
    }
   ],
   "source": [
    "# iterate through the batches\n",
    "for inputs, targets, target_ids in TrainingProvider:\n",
    "    \n",
    "    # inputs is a list with length equal to \n",
    "    # max number of questions any student in the data has answered\n",
    "    print(len(inputs))\n",
    "    \n",
    "    # the first element is the first question each student answered \n",
    "    # and has shape (1, num_students, length_of_feature_vector)\n",
    "    print(inputs[0].shape)\n",
    "    \n",
    "    # each student has a sequence of answer correctness labels\n",
    "    # for the problems they answered, with 0=correct, 1=incorrect.\n",
    "    # Targets is a flattened array containing all these scores, so\n",
    "    # is length \\sum_i num_questions_answered_by_student_i\n",
    "    print(len(targets))\n",
    "    \n",
    "    # ids of the questions answered (need to extract a predictions\n",
    "    # after training), should be same shape as targets\n",
    "    print(len(target_ids))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "print(TrainingProvider.max_prob_set_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> d18c7e7306304373387d2dde163ae84dd1524bb2
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "train data provider has 2483 students\n",
      "val data provider has 621 students\n",
      "----------------\n",
      "FOLD 2\n",
      "train data provider has 2483 students\n",
      "val data provider has 621 students\n",
      "----------------\n",
      "FOLD 3\n",
      "train data provider has 2483 students\n",
      "val data provider has 621 students\n",
      "----------------\n",
      "FOLD 4\n",
      "train data provider has 2483 students\n",
      "val data provider has 621 students\n",
      "----------------\n",
      "FOLD 5\n",
      "train data provider has 2484 students\n",
      "val data provider has 620 students\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# example of how to use cross-validiation\n",
    "i = 1\n",
    "for data_provider_train, data_provider_val in TrainingProvider.get_k_folds(5):\n",
    "    print('FOLD {}'.format(i))\n",
    "    print('train data provider has {} students'.format(data_provider_train.inputs.shape[0]))\n",
    "    print('val data provider has {} students'.format(data_provider_val.inputs.shape[0]))\n",
    "    print('----------------')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on how data is represented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3104, 285089)\n"
     ]
    }
   ],
   "source": [
    "# entire dataset `.inputs` is stored as a spare matrix \n",
    "train_set = TrainingProvider.inputs.todense()\n",
    "\n",
    "# sparse matrix must be 2D, so has shape \n",
    "# (num_students, (2*max_question_id)+1 * max_number_of_questions_answered)\n",
    "print(train_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each row of data is a student \n",
    "    - So, matrix has first dimension = num_students\n",
    "- Each each column is an \"answer label\" (incorrect/correct) to a question, and the number of columns is the maximum number of questions any student answered \n",
    "    - So, matrix has second dimension = max_number_of_questions_answered \n",
    "    - Example: Student_A answered more questions than anyone else, answering 100 questions. The matrix has 100 columns, and Student_B who answered only 90 questions, has zeros in the last 10 columns.\n",
    "- However, each \"answer label\" is encoded as a one-hot vector in the following way:\n",
    "    - there are max_question_id number of questions, e.g. 15 different questions\n",
    "    - let the vector 'is_incorrrect' be a one-hot vector with 1 in the i^th position is a student got question with id number i incorrect\n",
    "    - let the vector 'is_corrrect' be a one-hot vector with 1 in the i^th position is a student got question with id number i correct\n",
    "    - each \"answer label\" is the represented by the vector [is_incorrrect, is_correct], which has length 2*max_question_id\n",
    "    - this vector is left-padded with a zero (I don't know why...)\n",
    "    - So, each \"answer label\" is a one-hot vecotr of length (2 $\\times$ max_question_id)+1\n",
    "    - So, matrix has second dimension = \n",
    "    (2 $\\times$ max_question_id)+1 $\\times$ \n",
    "    max_number_of_questions_answered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.2"
=======
   "version": "3.6.4"
>>>>>>> d18c7e7306304373387d2dde163ae84dd1524bb2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
