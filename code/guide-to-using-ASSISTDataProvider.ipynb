{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code based on [this code](https://github.com/siyuanzhao/2016-EDM) used in paper \"[Going Deeper with Deep Knowledge Tracing](http://www.educationaldatamining.org/EDM2016/proceedings/paper_133.pdf)\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ASSISTment Data is collected from a web-based automated math tutoring system. Core features include student id, question id & whether or not their answer was correct. \n",
    "\n",
    "There is [a dataset from 2009](https://sites.google.com/site/assistmentsdata/home/assistment-2009-2010-data/skill-builder-data-2009-2010) and is [a dataset from 2015](https://sites.google.com/site/assistmentsdata/home/2015-assistments-skill-builder-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ASSISTDataProvider has a couple of modifications compared to the usual DataProvider.\n",
    " - You need to give it the path to the directory containing the .npz files\n",
    " - you can tell it which_year ('09' or '15')\n",
    " - For each batch, it produces inputs, targets AND target_ids.  \n",
    "     - The target_ids contain indices for extracting a predictions vector from the output of the RNN (exactly like the 2016-EDM code).\n",
    " - There is no .npz file for the validation set. \n",
    "  - Instead, we use k-fold cross validation by first constructing a DataProvider using the training data, and then calling get_k_folds method, which returns k tuples of DataProviders: (train_dp, val_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_provider import ASSISTDataProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your path to directory containing data files\n",
    "DATA_DIR = '/home/ben/mlp/mlp-group-project/data/assist09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size is the number students included in each training batch\n",
    "TrainingProvider = ASSISTDataProvider(DATA_DIR, batch_size=10, use_plus_minus_feats=True, use_compressed_sensing=False, \n",
    "                                     shuffle_order=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time steps: 973, feat len: 293\n",
      "104 -1\n",
      "102 1.0\n",
      "138 -1\n",
      "104 1.0\n",
      "138 1.0\n",
      "104 -1\n",
      "27 1.0\n",
      "28 -1\n",
      "28 -1\n",
      "28 -1\n",
      "28 1.0\n",
      "28 -1\n",
      "3 1.0\n",
      "120 1.0\n",
      "120 1.0\n",
      "120 1.0\n",
      "120 1.0\n",
      "120 1.0\n",
      "130 1.0\n",
      "133 1.0\n",
      "133 1.0\n",
      "133 1.0\n",
      "133 -1\n",
      "133 1.0\n",
      "133 1.0\n",
      "133 1.0\n",
      "133 -1\n",
      "133 1.0\n",
      "133 1.0\n",
      "answered 29 questions\n"
     ]
    }
   ],
   "source": [
    "# batch_size is the number students included in each training batch\n",
    "TrainingProvider = ASSISTDataProvider(DATA_DIR, batch_size=10, use_plus_minus_feats=False, use_compressed_sensing=False, \n",
    "                                     shuffle_order=False)\n",
    "\n",
    "train = TrainingProvider.inputs.toarray()\n",
    "\n",
    "max_time_steps = TrainingProvider.max_num_ans\n",
    "feature_len = TrainingProvider.encoding_dim\n",
    "n_distict_questions = TrainingProvider.max_prob_set_id\n",
    "print('time steps: {}, feat len: {}'.format(max_time_steps, feature_len))\n",
    "\n",
    "train = train.reshape(-1, max_time_steps, feature_len)\n",
    "train.shape\n",
    "\n",
    "for i in range(max_time_steps):\n",
    "    argmax = np.argmax(np.abs(train[student, i]))\n",
    "    if argmax==0:\n",
    "        print('answered {} questions'.format(i))\n",
    "        break\n",
    "    if argmax > n_distict_questions:\n",
    "        print(argmax - n_distict_questions, train[student, i, argmax])\n",
    "    else:\n",
    "        print(argmax, -int(train[student, i, argmax]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time steps: 973, feat len: 147\n",
      "104 -1\n",
      "102 1\n",
      "138 -1\n",
      "104 1\n",
      "138 1\n",
      "104 -1\n",
      "27 1\n",
      "28 -1\n",
      "28 -1\n",
      "28 -1\n",
      "28 1\n",
      "28 -1\n",
      "3 1\n",
      "120 1\n",
      "120 1\n",
      "120 1\n",
      "120 1\n",
      "120 1\n",
      "130 1\n",
      "133 1\n",
      "133 1\n",
      "133 1\n",
      "133 -1\n",
      "133 1\n",
      "133 1\n",
      "133 1\n",
      "133 -1\n",
      "133 1\n",
      "133 1\n",
      "answered 29 questions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size is the number students included in each training batch\n",
    "TrainingProvider = ASSISTDataProvider(DATA_DIR, batch_size=10, use_plus_minus_feats=True, use_compressed_sensing=False, \n",
    "                                     shuffle_order=False)\n",
    "\n",
    "train = TrainingProvider.inputs.toarray()\n",
    "\n",
    "max_time_steps = TrainingProvider.max_num_ans\n",
    "feature_len = TrainingProvider.encoding_dim\n",
    "print('time steps: {}, feat len: {}'.format(max_time_steps, feature_len))\n",
    "\n",
    "train = train.reshape(-1, max_time_steps, feature_len)\n",
    "train.shape\n",
    "\n",
    "for i in range(max_time_steps):\n",
    "    argmax = np.argmax(np.abs(train[student, i]))\n",
    "    if argmax==0:\n",
    "        print('answered {} questions'.format(i))\n",
    "        break\n",
    "    print(argmax, train[student, i, argmax])\n",
    "    \n",
    "train[student, 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time steps: 973, feat len: 100\n",
      "99 2.57306406282\n",
      "66 -2.78007257718\n",
      "80 1.97280070664\n",
      "22 2.84318295174\n",
      "93 2.49173785056\n",
      "99 2.57306406282\n",
      "51 -2.86604934833\n",
      "15 -4.18810237931\n",
      "15 -4.18810237931\n",
      "15 -4.18810237931\n",
      "49 -2.78600587859\n",
      "15 -4.18810237931\n",
      "18 2.75653670855\n",
      "25 -2.68611063405\n",
      "25 -2.68611063405\n",
      "25 -2.68611063405\n",
      "25 -2.68611063405\n",
      "25 -2.68611063405\n",
      "89 -2.85447816076\n",
      "63 -3.00661492065\n",
      "63 -3.00661492065\n",
      "63 -3.00661492065\n",
      "57 3.14860699624\n",
      "63 -3.00661492065\n",
      "63 -3.00661492065\n",
      "63 -3.00661492065\n",
      "57 3.14860699624\n",
      "63 -3.00661492065\n",
      "63 -3.00661492065\n",
      "answered 29 questions\n"
     ]
    }
   ],
   "source": [
    "# batch_size is the number students included in each training batch\n",
    "TrainingProvider = ASSISTDataProvider(DATA_DIR, which_set='train', batch_size=10, use_plus_minus_feats=False, use_compressed_sensing=True, \n",
    "                                     shuffle_order=False)\n",
    "\n",
    "train = TrainingProvider.inputs.toarray()\n",
    "\n",
    "max_time_steps = TrainingProvider.max_num_ans\n",
    "feature_len = TrainingProvider.encoding_dim\n",
    "print('time steps: {}, feat len: {}'.format(max_time_steps, feature_len))\n",
    "\n",
    "train = train.reshape(-1, max_time_steps, feature_len)\n",
    "train.shape\n",
    "\n",
    "for i in range(max_time_steps):\n",
    "    argmax = np.argmax(np.abs(train[student, i]))\n",
    "    if argmax==0:\n",
    "        print('answered {} questions'.format(i))\n",
    "        break\n",
    "    print(argmax, train[student, i, argmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 973, 100)\n",
      "398\n",
      "1420580\n"
     ]
    }
   ],
   "source": [
    "# iterate through the batches\n",
    "for inputs, targets, target_ids in TrainingProvider:    \n",
    "    # inputs has shape (batch_size, num_students, length_of_feature_vector)\n",
    "    print(inputs.shape)\n",
    "    \n",
    "    # each student has a sequence of answer correctness labels\n",
    "    # for the problems they answered, with 0=correct, 1=incorrect.\n",
    "    # Targets is a flattened array containing all these scores, so\n",
    "    # is length \\sum_i num_questions_answered_by_student_i\n",
    "    print(len(targets))\n",
    "    \n",
    "    # ids of the questions answered (need to extract a predictions\n",
    "    # after training), should be same shape as targets\n",
    "    print(len(target_ids))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "train data provider has 2483 students\n",
      "val data provider has 621 students\n",
      "----------------\n",
      "FOLD 2\n",
      "train data provider has 2483 students\n",
      "val data provider has 621 students\n",
      "----------------\n",
      "FOLD 3\n",
      "train data provider has 2483 students\n",
      "val data provider has 621 students\n",
      "----------------\n",
      "FOLD 4\n",
      "train data provider has 2483 students\n",
      "val data provider has 621 students\n",
      "----------------\n",
      "FOLD 5\n",
      "train data provider has 2484 students\n",
      "val data provider has 620 students\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# example of how to use cross-validiation\n",
    "i = 1\n",
    "for data_provider_train, data_provider_val in TrainingProvider.get_k_folds(5):\n",
    "    print('FOLD {}'.format(i))\n",
    "    print('train data provider has {} students'.format(data_provider_train.inputs.shape[0]))\n",
    "    print('val data provider has {} students'.format(data_provider_val.inputs.shape[0]))\n",
    "    print('----------------')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on how data is represented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3104, 97300)\n"
     ]
    }
   ],
   "source": [
    "# entire dataset `.inputs` is stored as a spare matrix \n",
    "train_set = TrainingProvider.inputs.todense()\n",
    "\n",
    "# sparse matrix must be 2D, so has shape \n",
    "# (num_students, (2*max_question_id)+1 * max_number_of_questions_answered)\n",
    "print(train_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each row of data is a student \n",
    "    - So, matrix has first dimension = num_students\n",
    "- Each each column is an \"answer label\" (incorrect/correct) to a question, and the number of columns is the maximum number of questions any student answered \n",
    "    - So, matrix has second dimension = max_number_of_questions_answered \n",
    "    - Example: Student_A answered more questions than anyone else, answering 100 questions. The matrix has 100 columns, and Student_B who answered only 90 questions, has zeros in the last 10 columns.\n",
    "- However, each \"answer label\" is encoded as a one-hot vector in the following way:\n",
    "    - there are max_question_id number of questions, e.g. 15 different questions\n",
    "    - let the vector 'is_incorrrect' be a one-hot vector with 1 in the i^th position is a student got question with id number i incorrect\n",
    "    - let the vector 'is_corrrect' be a one-hot vector with 1 in the i^th position is a student got question with id number i correct\n",
    "    - each \"answer label\" is the represented by the vector [is_incorrrect, is_correct], which has length 2*max_question_id\n",
    "    - this vector is left-padded with a zero (I don't know why...)\n",
    "    - So, each \"answer label\" is a one-hot vecotr of length (2 $\\times$ max_question_id)+1\n",
    "    - So, matrix has second dimension = \n",
    "    (2 $\\times$ max_question_id)+1 $\\times$ \n",
    "    max_number_of_questions_answered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.random.randn(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8.70398188,   -6.54481812],\n",
       "       [  32.55613273,  -14.95586609],\n",
       "       [  56.40828358,  -23.36691406],\n",
       "       [  80.26043444,  -31.77796202],\n",
       "       [ 104.11258529,  -40.18900999]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.arange(25).reshape(5,5), A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
