{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider import ASSISTDataProvider\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/ben/mlp/mlp-group-project/data/assist09'\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "TrainingSet = ASSISTDataProvider(DATA_DIR, batch_size=2, shuffle_order=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(array, dimensions=100, rng=None):\n",
    "    \"\"\"Embed array as a vector from a Standard Normal in dimensions.\n",
    "    \n",
    "    Only the last dimension of the data is affected.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dimensions : int (default=100)\n",
    "        DKT paper embeds one-hot inputs to 100 dims\n",
    "    rng : numpy.random.RandomState (default=None)\n",
    "    \"\"\"\n",
    "    if not rng:\n",
    "        rng = np.random.RandomState()\n",
    "    linear_map = rng.randn(data.shape[-1], dimensions)\n",
    "    return np.dot(data, linear_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmModel:\n",
    "    \n",
    "    def __init__(self, max_time_steps=973, feature_len=293):\n",
    "        self.max_time_steps = max_time_steps\n",
    "        self.feature_len = feature_len\n",
    "\n",
    "    def build_graph(self, n_hidden_layers=1, n_hidden_units=200, keep_prob=1.0):\n",
    "        \"\"\"Build a TensorFlow computational graph for an LSTM network.\n",
    "\n",
    "        Model based on \"DKT paper\" (see section 3): \n",
    "            Piech, Chris, et al. \"Deep knowledge tracing.\" \n",
    "            Advances in Neural Information Processing Systems. 2015.\n",
    "            \n",
    "        Implementation based on \"GD paper\" (see section 3): \n",
    "            Xiong, Xiaolu, et al. \"Going Deeper with Deep Knowledge Tracing.\"\n",
    "            EDM. 2016.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_hidden_layers : int (default=1)\n",
    "            A single hidden layer was used in DKT paper\n",
    "        n_hidden_units : int (default=200)\n",
    "            200 hidden units were used in DKT paper\n",
    "        keep_prob : float in [0, 1] (default=1.0)\n",
    "            Probability a unit is kept in dropout layer\n",
    "        \"\"\"\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        # data. 'None' means any length batch size accepted\n",
    "        self.inputs = tf.placeholder(\n",
    "            tf.float32, \n",
    "            shape=[self.max_time_steps, None, self.feature_len], \n",
    "            name='inputs')\n",
    "        \n",
    "        self.targets = tf.placeholder(tf.float32, \n",
    "                                      shape=[None], \n",
    "                                      name='targets')\n",
    "        \n",
    "        # int type required for tf.gather function\n",
    "        self.target_ids = tf.placeholder(tf.int32, \n",
    "                                         shape=[None], \n",
    "                                         name='target_ids')\n",
    "\n",
    "        # model. LSTM layer(s) then linear layer (softmax applied in loss)\n",
    "        cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden_units)\n",
    "        if keep_prob < 1:\n",
    "            cell = tf.nn.rnn_cell.DropoutWrapper(cell, keep_prob)\n",
    "        if n_hidden_layers > 1:\n",
    "            cells = [cell for layer in n_hidden_layers]\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "        \n",
    "        #x = tf.reshape(self.inputs, [-1, self.feature_len])\n",
    "        #x = tf.split(x, self.max_time_steps, 0)\n",
    "        self.outputs, self.state = tf.nn.dynamic_rnn(cell=cell,\n",
    "                                                     inputs=self.inputs,\n",
    "                                                     dtype=tf.float32,\n",
    "                                                    time_major=True)\n",
    "        \n",
    "        sigmoid_w = tf.get_variable(dtype=tf.float32,\n",
    "                                    name=\"sigmoid_w\", \n",
    "                                    shape=[n_hidden_units, \n",
    "                                           self.feature_len])\n",
    "        sigmoid_b = tf.get_variable(dtype=tf.float32,\n",
    "                                    name=\"sigmoid_b\", \n",
    "                                    shape=[self.feature_len])\n",
    "        \n",
    "        # reshaping as done in GD paper code \n",
    "        self.outputs = tf.concat(self.outputs, axis=1)\n",
    "        self.outputs = tf.reshape(self.outputs, \n",
    "                                  shape=[-1, n_hidden_units])\n",
    "        logits = tf.matmul(self.outputs, sigmoid_w) + sigmoid_b\n",
    "        \n",
    "        # reshaping as done in GD paper code \n",
    "        logits = tf.reshape(logits, [-1])\n",
    "        logits = tf.gather(logits, self.target_ids)\n",
    "        \n",
    "        # loss\n",
    "        self.loss = tf.reduce_mean(\n",
    "            tf.losses.softmax_cross_entropy(\n",
    "                logits=logits, onehot_labels=self.targets))\n",
    "        learning_rate = 1e-10\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        self.objective = optimizer.minimize(self.loss)\n",
    "        \n",
    "        # predictions\n",
    "        self.predictions = tf.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "Model = LstmModel()\n",
    "Model.build_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    92    238    384    530    698    844    990   1136   1281   1427\n",
      "   1573   1719   1865   2011   2157   2303   2449   2595   2737   2867\n",
      "   3013   3159   3305   3451   3597   3743   3889   4035   4181   4334\n",
      "   4480   4626   4772   4932   5078   5224   5370   5516   5641   5787\n",
      "   5933   6079   6225   6371   6517   6663   6809   6955   7101   7247\n",
      "   7438   7587   7733   7879   8025   8171   8317   8451   8597   8743\n",
      "   8889   9035   9181   9327   9346   9492   9638   9784   9954  10169\n",
      "  10315  10478  10598  10716  10889  11035  11181  11327  11473  11619\n",
      "  11765  11865  12011  12157  12303  12414  12560  12822  12968  12998\n",
      "  13272  13333  13433  13579  13780  13912  14058  14246  14308  14504\n",
      "  14650  14796  14942  15088  15268  15414  15560  15706  15852  16034\n",
      "  16144  16206  16403  16543  16750  16896  16967  17113  17334  17424\n",
      "  17653  17799  17945  18091  18193  18304  18485  18596  18777  18899\n",
      "  19069  19242  19330  19476  19610  19751  19897  20103  20284  20418\n",
      "  20564  20710  20856  21002  21148  21272  21379  21525  21673  21817\n",
      " 142141 142287 142433 142579 142725 142871 143017 143163 143309]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0e4a70b9da13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# quit after 10 batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "#     train_saver = tf.train.Saver()\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    losses = []\n",
    "    i = 0\n",
    "    for epoch in range(10): \n",
    "        \n",
    "        for inputs, targets, target_ids in TrainingSet:\n",
    "            inputs = np.squeeze(np.array(inputs, dtype=np.float32))\n",
    "            targets = np.array(targets, dtype=np.float32)\n",
    "            target_ids = np.array(target_ids, dtype=np.int32)\n",
    "            print(target_ids)\n",
    "            \n",
    "            # Train!\n",
    "            _, loss = sess.run(\n",
    "                [Model.objective, Model.loss],\n",
    "                feed_dict={Model.inputs: inputs,\n",
    "                           Model.targets: targets,\n",
    "                           Model.target_ids: target_ids})\n",
    "            \n",
    "            losses.append(loss)\n",
    "            \n",
    "            i += 1\n",
    "            if i == 1:  # quit after 10 batches\n",
    "                raise\n",
    "            \n",
    "            \n",
    "#         save model\n",
    "#         save_path = \"{}/{}_{}.ckpt\".format(\n",
    "#             MODELS_DIR, experiment_name, epoch)\n",
    "#         train_saver.save(sess, save_path)    tdrop        \n",
    "#     print(\"Saved model at\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "149*146 + 63 - 21817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23151"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "150*146 + 8*146 + 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "146*2 + 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
