{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to remotely connect to Dice and GPU cluster?\n",
    "\n",
    "Before starting, we have three types of server as follows. \n",
    "    1. Local sever (your labtop)\n",
    "    2. Dice server (+ shared server)\n",
    "    3. GPU server\n",
    "    \n",
    "### 1. From local to Dice\n",
    "\n",
    "You can connect to the Dice machine on you local server using this command."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> ssh [your_student_number]@student.ssh.inf.ed.ac.uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this command, you should type your dice password once. \n",
    "And then, you should log in to shared server on Dice server with next command. After that, you can activate your mlp virtual environment. If you successfully connected to shared server, you can check that the name of server changed. (e.g. ashbury:~$ )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> ssh student.compute\n",
    ">> source activate mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using Jupyter Notebook on your Local server\n",
    "\n",
    "Since jupyter notebook is run via firefox, you should use a specific command line to open jupyter notebook. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> nice -n 19 jupyter notebook --no-browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you type the command above, you will be able to know local host number through NotebookApp."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[I 16:12:22.104 NotebookApp] The Jupyter Notebook is running at: http://localhost:8888/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Then come back to your local server and open another terminal.* In order to open jupyter notbook on your local firefox, you can use a command below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> ssh -N -o ProxyCommand=\"ssh -q [your_student_number]@student.ssh.inf.ed.ac.uk nc ashbury.inf.ed.ac.uk 22\" -L [Any_localhost_number_you_want]:localhost:[Dice_server_localhost_number] [your_student_number]@[name_of_server].inf.ed.ac.uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be confused about the long command...\n",
    "My example is as follows.\n",
    "\n",
    "\n",
    "\n",
    "[Any_localhost_number_you_want] = 8880\n",
    "\n",
    "[Dice_server_localhost_number] = 8888 (This is the number informed at last step.)\n",
    "\n",
    "[name_of_server] = ashbury\n",
    "\n",
    "\n",
    "Finally, you can open jupyter notebook on your local firefox via address \"localhost:[Any_localhost_number_you_want]\". (Type this line at address bar.)\n",
    "\n",
    "At first, you might need to set a password for jupyter notbook because of security problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. From Dice to GPU server\n",
    "\n",
    "*Let's comback to dice server terminal.*\n",
    "You can connect to GPU server using one of both command lines. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> ssh mlp1\n",
    "\n",
    "OR\n",
    "\n",
    ">> ssh mlp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're on gpu server(=gpu cluster) and need to set gpu environment once following commands below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "\n",
    ">> bash Miniconda3-latest-Linux-x86_64.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During installation, you should type \"yes\" for first question and press ENTER for next question. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Do you accept the license terms? [yes|no]\n",
    "[no] >>> yes\n",
    "\n",
    "--------------------------------------------------------------\n",
    "\n",
    "Miniconda3 will now be installed into this location:\n",
    "/home/sxxxxxxx/miniconda3\n",
    "\n",
    "  - Press ENTER to confirm the location\n",
    "  - Press CTRL-C to abort the installation\n",
    "  - Or specify a different location below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you should follow commands below to finish setup."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> source .bashrc\n",
    "\n",
    ">> source activate\n",
    "\n",
    ">> conda create -n mlp python=3\n",
    "\n",
    ">> source activate mlp\n",
    "\n",
    ">> conda install git\n",
    "\n",
    ">> git clone https://github.com/CSTR-Edinburgh/mlpractical.git.\n",
    "\n",
    ">> git checkout mlp2017-8/semester_2_materials.\n",
    "\n",
    ">> cd mlpractical\n",
    "\n",
    ">> pip install -r requirements_gpu.txt.\n",
    "   \n",
    ">> cd ~/miniconda3/envs/mlp\n",
    "\n",
    ">> mkdir -p ./etc/conda/activate.d\n",
    "\n",
    ">> mkdir -p ./etc/conda/deactivate.d\n",
    "\n",
    ">> echo -e '#!/bin/sh\\n' >> ./etc/conda/activate.d/env_vars.sh\n",
    "\n",
    ">> echo \"export MLP_DATA_DIR=$HOME/mlpractical/data\" >> ./etc/conda/activate.d/env_vars.sh\n",
    "\n",
    ">> echo -e '#!/bin/sh\\n' >> ./etc/conda/deactivate.d/env_vars.sh\n",
    "\n",
    ">> echo 'unset MLP_DATA_DIR' >> ./etc/conda/deactivate.d/env_vars.sh\n",
    "\n",
    ">> export MLP_DATA_DIR=$HOME/mlpractical/data\n",
    "\n",
    ">> conda clean -t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use both servers, mlp1 and mlp2, you should set gpu environment on every two servers. \n",
    "\n",
    "Whenever you login to the cluster, remember to run:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> source .bashrc\n",
    ">> source activate mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install scipy, sklearn and matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy your data and code up to the cluster. To do this, simply use the following command, adding data_directory, cluster_number (1 or 2, whichever you are set up on) and student_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -r <data_directory> mlp<cluster_number>:/home/<student_id>\n",
    "rsync -r <code_directory> mlp<cluster_number>:/home/<student_id>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you successfully set your gpu environment. Before running experiments, create the necessary directories with the following script, passing in the start and end numbers for your experiments (see --model_dir column of our google spreadsheet to see which experiment numbers you've been assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "START=$1\n",
    "END=$2\n",
    "for ((i=$START; i<=$END; i++)); do\n",
    "   mkdir -p experiments/experiment\"$i\"/err\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, because of the way slurm works, we need to generate a new script for every setting of the hyperparams (you'd think you could just pass new hyperparams as an argument to the same script, but I (ben) couldn't get this to work. Neither could Luke in my office, and he seems to know what he is doing.\n",
    "\n",
    "So, below is a bash script that generates bash scripts that we can give to slurm. You need to pass it two arguments:\n",
    "* a text file where each new line is a python command copied from the google sheet\n",
    "* the experiment number (see google sheet) of the first python command.\n",
    "\n",
    "Note: the script below assumes that your python commands correspond to consecutive experiment numbers."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "COMMAND_FILE=$1\n",
    "START=$2\n",
    "COUNTER=$START\n",
    "mkdir -p train_scripts/complete\n",
    "while read p; do\n",
    "   str='#!/bin/sh\n",
    "#SBATCH -N 1\t  # nodes requested\n",
    "#SBATCH -n 1\t  # tasks requested\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --mem=16000  # memory in Mb\n",
    "#SBATCH -o experiments/experiment'\"$COUNTER\"'/out_file # see --model_dir column in our 'mlp-group-experiments' google sheet\n",
    "#SBATCH -e experiments/experiment'\"$COUNTER\"'/err/err_file# send stderr to sample_experiment_errfile\n",
    "export CUDA_HOME=/opt/cuda-8.0.44\n",
    "export CUDNN_HOME=/opt/cuDNN-6.0_8.0\n",
    "export STUDENT_ID=$(whoami)\n",
    "export LD_LIBRARY_PATH=${CUDNN_HOME}/lib64:${CUDA_HOME}/lib64:$LD_LIBRARY_PATH\n",
    "export LIBRARY_PATH=${CUDNN_HOME}/lib64:$LIBRARY_PATH\n",
    "export CPATH=${CUDNN_HOME}/include:$CPATH\n",
    "export PATH=${CUDA_HOME}/bin:${PATH}\n",
    "export PYTHON_PATH=$PATH\n",
    "mkdir -p /disk/scratch/${STUDENT_ID}\n",
    "export TMPDIR=/disk/scratch/${STUDENT_ID}/\n",
    "export TMP=/disk/scratch/${STUDENT_ID}/\n",
    "# Activate the relevant virtual environment:\n",
    "source /home/${STUDENT_ID}/miniconda3/bin/activate mlp\n",
    "'\"$p\"\n",
    "   echo \"$str\" > train_scripts/run_training\"$COUNTER\".sh\n",
    "   COUNTER=$((COUNTER+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now you have a directory called 'train_scripts' containing the scripts we need to pass to slurm. We can pass them all in one go with the following script (which automatically moves them into the 'complete' subfolder afterwards, so that we don't accidentally run them again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "for filename in ~/train_scripts/*.sh; do\n",
    "   sbatch $filename\n",
    "   mv $filename ~/train_scripts/complete\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your jobs, run:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> squeue | grep <student_id>\n",
    "(This is a command to check all your jobs on the gpu cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if you don't want your job on gpu cluster to be automatically cancelled when exiting ssh, you can use nohup and longjob."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(echo '<your_dice_password>' | nohup longjob -28day -c 'sbatch script.sh' > nohup.out) &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your experiments have completed, you want to be able to quickly check the results and paste the final AUCs into the google sheet. Here is a script that helps you do that. It does 3 things:\n",
    "\n",
    "* creates a results.txt file containing the output of the final 20 epochs of each experiment you ran. It automatically reorders the output so that training outputs are listed first, and then validation ouputs are listed (rather than continually alternating making it hard to read).\n",
    "\n",
    "* creates a final_train_auc.txt that contains the final AUC score for each experiment on the training data. this can be directly copied and pasted into the corresponding column in the google doc.\n",
    "\n",
    "* creates a final_val_auc.txt that does the same as above, but for validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "START=$1\n",
    "END=$2\n",
    "\n",
    "# reset files\n",
    "> results.txt\n",
    "> final_train_auc.txt\n",
    "> final_val_auc.txt\n",
    "\n",
    "for ((i=$START; i<=$END; i++)); do\n",
    "   echo '=====================================================================\n",
    "                   EXPERIMENT' \"$i\" '\n",
    "=====================================================================' >> results.txt\n",
    "   tail -n 41 experiments/experiment\"$i\"/out_file | awk 'NR % 2 == 1' >> results.txt\n",
    "   echo '---------------------------------------------------------------------' >> results.txt\n",
    "   tail -n 41 experiments/experiment\"$i\"/out_file | awk 'NR % 2 == 0' >> results.txt\n",
    "   tail -n 3 experiments/experiment\"$i\"/out_file | awk 'NR % 2 == 1' | grep -Po \"(?<=AUC: ).*(?= \\()\" >> final_train_auc.txt\n",
    "   tail -n 3 experiments/experiment\"$i\"/out_file | awk 'NR % 2 == 0' | grep -Po \"(?<=AUC: ).*(?= \\()\" >> final_val_auc.txt\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally you can copy your result from gpu server to your dice server. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> cp [your_result_file] /afs/inf.ed.ac.uk/u/s/[your_student_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
